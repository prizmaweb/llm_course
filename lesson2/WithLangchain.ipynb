{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-classic in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain) (1.2.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.5.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-classic) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from langchain-classic) (2.0.45)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 1.2.0\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://docs.langchain.com/\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/adeb/llm_engineering/llms/lib/python3.11/site-packages\n",
      "Requires: langchain-core, langgraph, pydantic\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_classic.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmsykbKh8oth"
   },
   "source": [
    "## Chat API : LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mtiDVjTz7pGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mEsqX2w-6ShZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x34d433fd0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x34dd17fd0>, root_client=<openai.OpenAI object at 0x30c7c9a10>, root_async_client=<openai.AsyncOpenAI object at 0x34dd17ad0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You donâ€™t need to pass the key explicitly in the api as an arg unless you want to override it\n",
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "llm_model=\"gpt-4o-mini\"\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "mGIb0ikG-cB3"
   },
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "U-LuC84o-fa7"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kQU1KBXD-rCK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5qDBKTjv-57_"
   },
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Meine Bestellung wurde nicht geliefert!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "p5QSY_Em_rl5"
   },
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AOVavJcH_rsT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sbfQzEYy6VS3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nMeine Bestellung wurde nicht geliefert!\\n```\\n' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "bKjlXiYhAE5G"
   },
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "E9yMLdry_0IK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My order has not been delivered.\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THCr9k2DAG5j"
   },
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "SK8nwl2JAWgv"
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Anirban. I work at Akamai.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello, Anirban! It's great to meet you. Akamai is known for its content delivery network and cloud services, right? What do you do there?\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Anirban. I work at Akamai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hIUxqguF6XMv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Anirban. I work at Akamai.\n",
      "AI: Hello, Anirban! It's great to meet you. Akamai is known for its content delivery network and cloud services, right? What do you do there?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"1 + 1 equals 2! It's a simple arithmetic problem, but it's always good to double-check the basics. Do you have any other questions or topics you'd like to discuss?\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "HXrNblnH7Zf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Anirban. I work at Akamai.\n",
      "AI: Hello, Anirban! It's great to meet you. Akamai is known for its content delivery network and cloud services, right? What do you do there?\n",
      "Human: What is 1+1?\n",
      "AI: 1 + 1 equals 2! It's a simple arithmetic problem, but it's always good to double-check the basics. Do you have any other questions or topics you'd like to discuss?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Your name is Anirban! It's nice to know your name. Is there anything specific you'd like to talk about today?\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "JWn9a2cN7ofj"
   },
   "outputs": [],
   "source": [
    "from langchain_classic.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, I am going to Tokyo tomorrow\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I am going to Tokyo tomorrow\n",
      "AI: That sounds exciting! Tokyo is such a vibrant city with so much to see and do. Do you have any specific plans or places you want to visit while you're there? There are amazing neighborhoods like Shibuya and Shinjuku, beautiful temples like Senso-ji, and delicious food to try, like sushi and ramen!\n",
      "Human: My luggage needs to be picked up from my Osaka hotel\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My luggage needs to be picked up from my Osaka hotel\n",
      "AI: Oh, I see! If you're traveling from Osaka to Tokyo, you might want to consider using a luggage delivery service. Many hotels in Osaka can help arrange for your luggage to be sent directly to your hotel in Tokyo, which can make your journey much easier. Just make sure to check with your hotel about their policies and any fees that might apply. Have you already booked your accommodation in Tokyo?\n",
      "Human: It needs to be delivered to the Akamai office near Tokyo station\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: It needs to be delivered to the Akamai office near Tokyo station\n",
      "AI: That sounds like a convenient plan! The Akamai office is located in the Marunouchi area, which is quite close to Tokyo Station. If you're using a luggage delivery service, just provide them with the exact address of the Akamai office, and they should be able to handle the rest. It's a good idea to inform the office about the delivery in advance, so they know to expect your luggage. Do you have a specific delivery service in mind, or would you like some recommendations?\n",
      "Human: Where am I going tomorrow ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm not sure where you're going tomorrow! If you have plans or a specific destination in mind, feel free to share, and I can help you with information or tips related to that place. Otherwise, if you need assistance with travel arrangements or suggestions, just let me know!\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, I am going to Tokyo tomorrow\")\n",
    "conversation.predict(input=\"My luggage needs to be picked up from my Osaka hotel\")\n",
    "conversation.predict(input=\"It needs to be delivered to the Akamai office near Tokyo station\")\n",
    "print(conversation.predict(input=\"Where am I going tomorrow ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
